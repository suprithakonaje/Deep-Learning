{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab1Exercise.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2kArhqHkPMm6"
      },
      "outputs": [],
      "source": [
        "# Execute this code block to install dependencies when running on colab\n",
        "try:\n",
        "    import torch\n",
        "except:\n",
        "    from os.path import exists\n",
        "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "    cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "    accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "    !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1 Implement gradient based factorisation "
      ],
      "metadata": {
        "id": "EmvoWcNVPgw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "def sgd_factorise(A: torch.Tensor, rank: int, num_epochs = 1000, lr = 0.01) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "  m, n = A.shape\n",
        "  U = torch.rand(m, rank)\n",
        "  V = torch.rand(n, rank)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    for r in range(m):\n",
        "      for c in range(n):\n",
        "        e = A[r, c] - U[r] @ V[c].T\n",
        "        U[r] = U[r] + lr * e * V[c]\n",
        "        V[c] = V[c] + lr * e * U[r]\n",
        "\n",
        "  return U, V"
      ],
      "metadata": {
        "id": "k3g8keo0PmzD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1 Factorise and compute reconstruction error"
      ],
      "metadata": {
        "id": "CT9wlZtVSDbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.tensor(\n",
        "    [[0.3374, 0.6005, 0.1735],\n",
        "     [3.3359, 0.0492, 1.8374],\n",
        "     [2.9407, 0.5301, 2.2620]])\n",
        "\n",
        "U, V = sgd_factorise(A, rank = 2)\n",
        "\n",
        "print(\"A = \" ,A) \n",
        "print(\"U = \" ,U)\n",
        "print(\"V = \" ,V)\n",
        "print()\n",
        "\n",
        "A_sgd = U @ V.T\n",
        "sgd_loss = torch.nn.functional.mse_loss(input = A_sgd , target = A, reduction = 'sum')\n",
        "print(sgd_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_sMj6bdWWzT",
        "outputId": "a6824db7-f22c-4ddb-e140-4eeda9b85084"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A =  tensor([[0.3374, 0.6005, 0.1735],\n",
            "        [3.3359, 0.0492, 1.8374],\n",
            "        [2.9407, 0.5301, 2.2620]])\n",
            "U =  tensor([[ 0.6087, -0.1197],\n",
            "        [ 0.4773,  1.6923],\n",
            "        [ 1.1350,  1.2965]])\n",
            "V =  tensor([[ 0.7014,  1.7256],\n",
            "        [ 0.7938, -0.2314],\n",
            "        [ 0.7831,  0.9428]])\n",
            "\n",
            "tensor(0.1221)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1 Compare  to the truncated SVD"
      ],
      "metadata": {
        "id": "Chanx7AJavI6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating reconstruction error using SVD"
      ],
      "metadata": {
        "id": "HusVvYyDeNj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "U, S, V = torch.svd(A)\n",
        "\n",
        "print(S.shape)\n",
        "S[2] = 0\n",
        "print(S)\n",
        "\n",
        "A_svd = U @ torch.diag(S) @ V.T\n",
        "\n",
        "print(A_svd)\n",
        "\n",
        "svd_loss = torch.nn.functional.mse_loss(A, A_svd, reduction='sum')\n",
        "print(svd_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf4zbdlaayXO",
        "outputId": "5be113ea-6651-4729-9966-2d4055d5db1a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3])\n",
            "tensor([5.3339, 0.6959, 0.0000])\n",
            "tensor([[ 0.2245,  0.5212,  0.3592],\n",
            "        [ 3.2530, -0.0090,  1.9737],\n",
            "        [ 3.0378,  0.5983,  2.1023]])\n",
            "tensor(0.1219)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the difference between the algorithm and SVD\n",
        "\n",
        "Eckart-Young-Mirsky Theorem: \n",
        "https://rich-d-wilkinson.github.io/MATH3030/3-5-lowrank.html"
      ],
      "metadata": {
        "id": "LGLgiTuNempW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diff = torch.norm(sgd_loss - svd_loss)\n",
        "print(diff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1etBYEve4M_",
        "outputId": "6a1e09be-9453-470b-ad4c-f818d79d4910"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0002)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1 Implement Masked Factorisation"
      ],
      "metadata": {
        "id": "35ZLQ5W6gtx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "def sgd_factorise_masked(A: torch.Tensor, M: torch.Tensor, rank: int, \n",
        "                         num_epochs = 1000, lr = 0.01) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "  m, n = A.shape\n",
        "  U = torch.rand(m, rank)\n",
        "  V = torch.rand(n, rank)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    for r in range(m):\n",
        "      for c in range(n):\n",
        "        if M[r, c] == 1:\n",
        "          e = A[r, c] - U[r] @ V[c].T\n",
        "          UOrigin = U[r]\n",
        "          U[r] = U[r] + lr * e * V[c]\n",
        "          V[c] = V[c] + lr * e * UOrigin\n",
        "\n",
        "  return U, V"
      ],
      "metadata": {
        "id": "9MkC719qgyFr"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2 Reconstruct a matrix"
      ],
      "metadata": {
        "id": "1RTARMMeinA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AWithNAN = torch.Tensor(\n",
        "    [[0.3374, 0.6005, 0.1735],\n",
        "     [torch.nan, 0.0492, 1.8374],\n",
        "     [2.9407, torch.nan, 2.2620]]\n",
        ")\n",
        "\n",
        "M = torch.Tensor(\n",
        "    [[1,1,1],\n",
        "     [0,1,1],\n",
        "     [1,0,1]]\n",
        ")\n",
        "\n",
        "U, V = sgd_factorise_masked(A, M, rank = 2) \n",
        "\n",
        "A_original = U @ V.T\n",
        "print(A_original)\n",
        "loss = torch.nn.functional.mse_loss(A_original, A, reduction='sum')\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg4FbUAzipp1",
        "outputId": "a10eeac6-aafe-4d35-8ce2-b01cf7aa62e6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3439, 0.5989, 0.1657],\n",
            "        [2.2581, 0.0494, 1.8358],\n",
            "        [2.9393, 0.7159, 2.2642]])\n",
            "tensor(1.1962)\n"
          ]
        }
      ]
    }
  ]
}